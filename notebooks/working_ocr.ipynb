{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thIlrV8AzgXU",
        "outputId": "348ecd1f-a5a5-4589-c0d3-ba51fa482a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.10 [186 kB]\n",
            "Fetched 186 kB in 0s (1,475 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.10_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "# Install poppler-utils for PDF processing\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p03KzE38zlVr",
        "outputId": "23ed87f6-5f3e-4725-ede7-06a58d9c1d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-doctr\n",
            "  Downloading python_doctr-1.0.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting paddleocr\n",
            "  Downloading paddleocr-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-3.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (0.23.0+cu126)\n",
            "Collecting onnx<3.0.0,>=1.12.0 (from python-doctr)\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (2.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (1.16.1)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (3.14.0)\n",
            "Collecting pypdfium2<5.0.0,>=4.11.0 (from python-doctr)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper<2.0.0,>=1.2.0 (from python-doctr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: shapely<3.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (2.1.1)\n",
            "Collecting langdetect<2.0.0,>=1.0.9 (from python-doctr)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from python-doctr)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (0.34.4)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (11.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (0.7.1)\n",
            "Collecting anyascii>=0.3.2 (from python-doctr)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting validators>=0.18.0 (from python-doctr)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from python-doctr) (4.67.1)\n",
            "Collecting paddlex<3.3.0,>=3.2.0 (from paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading paddlex-3.2.1-py3-none-any.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6 in /usr/local/lib/python3.12/dist-packages (from paddleocr) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from paddleocr) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from paddlepaddle) (0.28.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from paddlepaddle) (5.29.5)\n",
            "Collecting opt_einsum==3.3.0 (from paddlepaddle)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from paddlepaddle) (3.5)\n",
            "Requirement already satisfied: safetensors>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from paddlepaddle) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (1.1.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect<2.0.0,>=1.0.9->python-doctr) (1.17.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx<3.0.0,>=1.12.0->python-doctr) (0.5.3)\n",
            "Collecting aistudio_sdk>=0.3.5 (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading aistudio_sdk-0.3.7-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (5.2.0)\n",
            "Collecting colorlog (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting modelscope>=1.28.0 (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading modelscope-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (3.16.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.12/dist-packages (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (2.11.7)\n",
            "Collecting ruamel.yaml (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ujson (from paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.12/dist-packages (from paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (1.4.1)\n",
            "Collecting opencv-contrib-python==4.10.0.84 (from paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->python-doctr) (3.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from aistudio_sdk>=0.3.5->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (5.9.5)\n",
            "Collecting bce-python-sdk (from aistudio_sdk>=0.3.5->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading bce_python_sdk-0.9.46-py3-none-any.whl.metadata (416 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from aistudio_sdk>=0.3.5->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (8.2.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.28.0->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (2.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->python-doctr) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->python-doctr) (3.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (0.2.13)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pycryptodome>=3.8.0 (from bce-python-sdk->aistudio_sdk>=0.3.5->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from bce-python-sdk->aistudio_sdk>=0.3.5->paddlex<3.3.0,>=3.2.0->paddlex[ocr-core]<3.3.0,>=3.2.0->paddleocr) (1.0.0)\n",
            "Downloading python_doctr-1.0.0-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddleocr-3.2.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddlepaddle-3.2.0-cp312-cp312-manylinux1_x86_64.whl (189.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddlex-3.2.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aistudio_sdk-0.3.7-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.30.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bce_python_sdk-0.9.46-py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.6/352.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=a47d15cae5402380ace0a7126af0a31bb0d3e0f998972326b67511184d1b2d25\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: pyclipper, validators, ujson, ruamel.yaml.clib, rapidfuzz, pypdfium2, pycryptodome, pdf2image, opt_einsum, opencv-contrib-python, langdetect, colorlog, anyascii, ruamel.yaml, onnx, modelscope, bce-python-sdk, paddlepaddle, aistudio_sdk, paddlex, python-doctr, paddleocr\n",
            "  Attempting uninstall: opt_einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "Successfully installed aistudio_sdk-0.3.7 anyascii-0.3.3 bce-python-sdk-0.9.46 colorlog-6.9.0 langdetect-1.0.9 modelscope-1.30.0 onnx-1.19.0 opencv-contrib-python-4.10.0.84 opt_einsum-3.3.0 paddleocr-3.2.0 paddlepaddle-3.2.0 paddlex-3.2.1 pdf2image-1.17.0 pyclipper-1.3.0.post6 pycryptodome-3.23.0 pypdfium2-4.30.0 python-doctr-1.0.0 rapidfuzz-3.14.1 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12 ujson-5.11.0 validators-0.35.0\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Install requirements\n",
        "# -------------------------\n",
        "!pip install python-doctr paddleocr opencv-python pandas tabulate paddlepaddle pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1Jk97k4zm1u"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor\n",
        "from pdf2image import convert_from_path\n",
        "from paddleocr import PaddleOCR, LayoutDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwj4ZV-0Jvs"
      },
      "source": [
        "# Image Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u_dWYafznpB"
      },
      "outputs": [],
      "source": [
        "def convert_to_images(pdf_path):\n",
        "  out_dir = Path(\"ocr_test\")\n",
        "  out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "  # Convert first page to image\n",
        "  pages = convert_from_path(pdf_path, dpi=300)\n",
        "  for idx, i in enumerate(pages):\n",
        "    page_path = out_dir / f\"page{idx}.png\"\n",
        "    pages[idx].save(page_path, \"PNG\")\n",
        "    print(\"Saved:\", page_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LBBP41b0IuD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Denoising\n",
        "    gray = cv2.medianBlur(gray, 3)\n",
        "\n",
        "    # Contrast enhancement\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    gray = clahe.apply(gray)\n",
        "\n",
        "    # # Resize (optional)\n",
        "    # h, w = gray.shape\n",
        "    # if max(h, w) < 1024:\n",
        "    #     gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return gray\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-PE4SJv1GtI"
      },
      "source": [
        "# Text Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35eVQ9vj1qwW"
      },
      "source": [
        "### 1. Text  Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5UW5Oik1rLO"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Tuple\n",
        "\n",
        "Word = Dict[str, object]  # {'text': str, 'bbox': Tuple[int, int, int, int]}\n",
        "\n",
        "# -----------------------------\n",
        "# 0. Preprocessing\n",
        "# -----------------------------\n",
        "def preprocess_words(words: List[Word]) -> List[Word]:\n",
        "    \"\"\"\n",
        "    Clean and normalize extracted words.\n",
        "    - Strip whitespace\n",
        "    - Remove empty text\n",
        "    - Ensure bounding boxes are integers\n",
        "    \"\"\"\n",
        "    processed = []\n",
        "    for w in words:\n",
        "        text = w[\"text\"].strip()\n",
        "        if text:\n",
        "            processed.append({\n",
        "                \"text\": text,\n",
        "                \"bbox\": tuple(map(int, w[\"bbox\"]))\n",
        "            })\n",
        "    return processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrSJLVrJ10IL"
      },
      "outputs": [],
      "source": [
        "def group_words_into_lines(words: List[Word], y_threshold: int = 10) -> List[List[Word]]:\n",
        "    \"\"\"\n",
        "    Group words into lines based on their y-coordinates.\n",
        "    - Sort words by top (y1) of bbox\n",
        "    - If difference in y < threshold, group into same line\n",
        "    \"\"\"\n",
        "    words = sorted(words, key=lambda w: (w[\"bbox\"][1], w[\"bbox\"][0]))  # sort by y, then x\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    prev_y = None\n",
        "\n",
        "    for w in words:\n",
        "        y_top = w[\"bbox\"][1]\n",
        "        if prev_y is None or abs(y_top - prev_y) <= y_threshold:\n",
        "            current_line.append(w)\n",
        "        else:\n",
        "            lines.append(sorted(current_line, key=lambda x: x[\"bbox\"][0]))  # align x\n",
        "            current_line = [w]\n",
        "        prev_y = y_top\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(sorted(current_line, key=lambda x: x[\"bbox\"][0]))\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QBYpvBY-vhI"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union, Dict\n",
        "\n",
        "Word = Dict[str, Union[str, tuple]]  # text + bbox\n",
        "Table = Dict[str, str]               # {\"table\": \"...\"}\n",
        "LineOrTable = Union[List[Word], Table]\n",
        "\n",
        "\n",
        "def group_words_and_tables_into_lines(\n",
        "    items: List[Union[Word, Table]], y_threshold: int = 10\n",
        ") -> List[LineOrTable]:\n",
        "    \"\"\"\n",
        "    Group OCR results (words + tables) into structured lines.\n",
        "\n",
        "    - Words are grouped into lines based on their y-coordinates.\n",
        "    - Tables are kept as-is, placed in sequence.\n",
        "    - Returns a mix of grouped word-lines and table dicts.\n",
        "    \"\"\"\n",
        "    # Separate words and tables but maintain sequence\n",
        "    output = []\n",
        "    buffer_words = []\n",
        "\n",
        "    def flush_words():\n",
        "        \"\"\"Group accumulated words into lines and push to output.\"\"\"\n",
        "        nonlocal buffer_words\n",
        "        if not buffer_words:\n",
        "            return\n",
        "        words_sorted = sorted(buffer_words, key=lambda w: (w[\"bbox\"][1], w[\"bbox\"][0]))\n",
        "        lines = []\n",
        "        current_line = []\n",
        "        prev_y = None\n",
        "        for w in words_sorted:\n",
        "            y_top = w[\"bbox\"][1]\n",
        "            if prev_y is None or abs(y_top - prev_y) <= y_threshold:\n",
        "                current_line.append(w)\n",
        "            else:\n",
        "                lines.append(sorted(current_line, key=lambda x: x[\"bbox\"][0]))\n",
        "                current_line = [w]\n",
        "            prev_y = y_top\n",
        "        if current_line:\n",
        "            lines.append(sorted(current_line, key=lambda x: x[\"bbox\"][0]))\n",
        "        output.extend(lines)\n",
        "        buffer_words = []\n",
        "\n",
        "    for item in items:\n",
        "        if isinstance(item, dict) and \"table\" in item:\n",
        "            # Flush pending words before inserting table\n",
        "            flush_words()\n",
        "            output.append(item)  # keep table as-is\n",
        "        else:\n",
        "            buffer_words.append(item)\n",
        "\n",
        "    # Flush remaining words\n",
        "    flush_words()\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XauMn6p14dj"
      },
      "outputs": [],
      "source": [
        "def merge_line_text(line: List[Word]) -> str:\n",
        "    \"\"\"Merge words in a line into full text string.\"\"\"\n",
        "    return \" \".join([w[\"text\"] for w in line])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-0NPGpP1Zmj"
      },
      "source": [
        "### 2. For Text Post-processing (Alignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFHcHoYp0FdH"
      },
      "outputs": [],
      "source": [
        "def get_leftmost_x(lines):\n",
        "    \"\"\"\n",
        "    Find the leftmost X-coordinate across all lines and words.\n",
        "\n",
        "    Args:\n",
        "        lines (list of list of dict]): OCR results.\n",
        "\n",
        "    Returns:\n",
        "        float: Minimum x-coordinate among all words.\n",
        "    \"\"\"\n",
        "    min_x = float('inf')\n",
        "    for line in lines:\n",
        "        for word in line:\n",
        "            min_x = min(min_x, word[\"bbox\"][0])\n",
        "    return min_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSRVxmC11NcB"
      },
      "outputs": [],
      "source": [
        "def get_line_indentation(line, leftmost_x, scale=100):\n",
        "    \"\"\"\n",
        "    Calculate indentation for a line relative to the leftmost word on the page.\n",
        "\n",
        "    Args:\n",
        "        line (list of dict]): Words in the line.\n",
        "        leftmost_x (float): X-coordinate of the leftmost word in the page.\n",
        "        scale (int): Factor to reduce pixel values to spaces.\n",
        "\n",
        "    Returns:\n",
        "        str: Spaces for indentation.\n",
        "    \"\"\"\n",
        "    if not line:\n",
        "        return \"\"\n",
        "\n",
        "    start_x = line[0][\"bbox\"][0]\n",
        "    indent = max(0, int((start_x - leftmost_x) / scale))\n",
        "    return \" \" * indent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4JMkNet1SNN"
      },
      "outputs": [],
      "source": [
        "def format_lines_with_spacing(lines, scale=100):\n",
        "    \"\"\"\n",
        "    Format OCR lines with proper spacing and page-relative indentation.\n",
        "\n",
        "    Args:\n",
        "        lines (list of list of dict]): OCR results.\n",
        "        scale (int): Factor to reduce pixel distances into spaces.\n",
        "\n",
        "    Returns:\n",
        "        str: Structured text formatted like the scanned page.\n",
        "    \"\"\"\n",
        "    formatted_output = []\n",
        "\n",
        "    # Find the leftmost x-coordinate of the page\n",
        "    leftmost_x = get_leftmost_x(lines)\n",
        "\n",
        "    for line in lines:\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Add indentation relative to page leftmost coordinate\n",
        "        line_text = get_line_indentation(line, leftmost_x, scale=scale)\n",
        "\n",
        "        for idx, word in enumerate(line):\n",
        "            if idx == len(line) - 1:\n",
        "                line_text += word[\"text\"]\n",
        "                break\n",
        "\n",
        "            # Calculate spacing between current word and next word\n",
        "            space = -1 * (line[idx][\"bbox\"][2] - line[idx + 1][\"bbox\"][0])\n",
        "            space = max(1, int(space / scale))\n",
        "\n",
        "            line_text += word[\"text\"] + (\" \" * space)\n",
        "\n",
        "        formatted_output.append(line_text)\n",
        "\n",
        "    return \"\\n\".join(formatted_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeMuJ3XD73Gr"
      },
      "outputs": [],
      "source": [
        "def render_text_and_tables_from_ocr(lines, scale=100):\n",
        "    \"\"\"\n",
        "    Format OCR output that may contain both text lines and tables.\n",
        "\n",
        "    Args:\n",
        "        lines (list of list of dict or dict]): OCR results after grouping.\n",
        "            - A line is a list of words (dicts with 'text' and 'bbox').\n",
        "            - A table is a dict with {\"table\": str}.\n",
        "        scale (int): Factor to reduce pixel distances into spaces.\n",
        "\n",
        "    Returns:\n",
        "        str: Structured text with tables preserved and text spaced properly.\n",
        "    \"\"\"\n",
        "    formatted_output = []\n",
        "\n",
        "    # Find leftmost x across all text words (ignore tables)\n",
        "    text_lines = [line for line in lines if isinstance(line, list)]\n",
        "    leftmost_x = get_leftmost_x(text_lines) if text_lines else 0\n",
        "\n",
        "    for line in lines:\n",
        "        if isinstance(line, dict) and \"table\" in line:\n",
        "            # Insert table as-is with spacing\n",
        "            formatted_output.append(\"\")\n",
        "            formatted_output.append(line[\"table\"])\n",
        "            formatted_output.append(\"\")\n",
        "            continue\n",
        "\n",
        "        if not line:  # empty line\n",
        "            continue\n",
        "\n",
        "        # Normal text line\n",
        "        line_text = get_line_indentation(line, leftmost_x, scale=scale)\n",
        "\n",
        "        for idx, word in enumerate(line):\n",
        "            if \"text\" not in word:\n",
        "                continue\n",
        "\n",
        "            if idx == len(line) - 1:\n",
        "                line_text += word[\"text\"]\n",
        "                break\n",
        "\n",
        "            # Calculate spacing between current word and next word\n",
        "            space = -1 * (line[idx][\"bbox\"][2] - line[idx + 1][\"bbox\"][0])\n",
        "            space = max(1, int(space / scale))\n",
        "            line_text += word[\"text\"] + (\" \" * space)\n",
        "\n",
        "        formatted_output.append(line_text)\n",
        "\n",
        "    return \"\\n\".join(formatted_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18LEwLcBFz5R"
      },
      "outputs": [],
      "source": [
        "# def format_lines_as_table(lines, scale=100, gap_threshold=3):\n",
        "#     \"\"\"\n",
        "#     Format OCR lines into a table using spacing from bounding boxes.\n",
        "\n",
        "#     Args:\n",
        "#         lines (list[list[dict]]): OCR results. Each line is a list of word dicts\n",
        "#                                   with {\"text\": str, \"bbox\": (x0, y0, x1, y1)}.\n",
        "#         scale (int): Scaling factor to convert pixel distances to spaces.\n",
        "#         gap_threshold (int): Minimum number of scaled spaces considered a new column.\n",
        "\n",
        "#     Returns:\n",
        "#         pd.DataFrame: Table reconstructed from OCR.\n",
        "#     \"\"\"\n",
        "#     table_rows = []\n",
        "\n",
        "#     for line in lines:\n",
        "#         if not line:\n",
        "#             continue\n",
        "\n",
        "#         row = []\n",
        "#         current_cell = line[0][\"text\"]\n",
        "\n",
        "#         for idx in range(len(line) - 1):\n",
        "#             this_word = line[idx]\n",
        "#             next_word = line[idx + 1]\n",
        "\n",
        "#             # spacing between this word and the next\n",
        "#             space = next_word[\"bbox\"][0] - this_word[\"bbox\"][2]\n",
        "#             space = max(0, int(space / scale))\n",
        "\n",
        "#             if space >= gap_threshold:\n",
        "#                 # treat as new column\n",
        "#                 row.append(current_cell.strip())\n",
        "#                 current_cell = next_word[\"text\"]\n",
        "#             else:\n",
        "#                 # same column → keep concatenating\n",
        "#                 current_cell += \" \" + next_word[\"text\"]\n",
        "\n",
        "#         row.append(current_cell.strip())\n",
        "#         table_rows.append(row)\n",
        "\n",
        "#     # Normalize to rectangular DataFrame\n",
        "#     max_cols = max(len(r) for r in table_rows)\n",
        "#     for r in table_rows:\n",
        "#         r.extend([\"\"] * (max_cols - len(r)))\n",
        "\n",
        "#     col_names = [f\"col{i+1}\" for i in range(max_cols)]\n",
        "#     df = pd.DataFrame(table_rows, columns=col_names)\n",
        "#     return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OSG9ZML5XOz"
      },
      "source": [
        "# Table Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3TFS-uM5ZR7"
      },
      "outputs": [],
      "source": [
        "# # Layout detection (text in tables)\n",
        "# def detect_table_content(img):\n",
        "#   layout_model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
        "#   layout_output = layout_model.predict(img, batch_size=1, layout_nms=True)\n",
        "\n",
        "#   table_boxes = []\n",
        "#   for res in layout_output:\n",
        "#       for box in res[\"boxes\"]:\n",
        "#           if box[\"label\"] == \"table\":\n",
        "#               coords = list(map(int, box[\"coordinate\"]))  # [x1,y1,x2,y2]\n",
        "#               table_boxes.append(tuple(coords))\n",
        "#   return table_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U8_gItiHfuK"
      },
      "outputs": [],
      "source": [
        "# --- Helper: Filter nested tables ---\n",
        "def filter_nested_tables(table_boxes):\n",
        "    \"\"\"\n",
        "    Removes tables that are fully inside larger table bounding boxes.\n",
        "\n",
        "    Args:\n",
        "        table_boxes (list of tuple): list of (x1,y1,x2,y2) table coordinates.\n",
        "\n",
        "    Returns:\n",
        "        list of tuple: filtered table boxes (no nested ones).\n",
        "    \"\"\"\n",
        "    # Sort by area (largest first)\n",
        "    table_boxes = sorted(table_boxes, key=lambda b: (b[2]-b[0]) * (b[3]-b[1]), reverse=True)\n",
        "\n",
        "    filtered_boxes = []\n",
        "    for box in table_boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        inside_other = False\n",
        "        for kept in filtered_boxes:\n",
        "            kx1, ky1, kx2, ky2 = kept\n",
        "            if x1 >= kx1 and y1 >= ky1 and x2 <= kx2 and y2 <= ky2:\n",
        "                inside_other = True\n",
        "                break\n",
        "        if not inside_other:\n",
        "            filtered_boxes.append(box)\n",
        "\n",
        "    return filtered_boxes\n",
        "\n",
        "\n",
        "# --- Main: Layout detection (text in tables) ---\n",
        "def detect_table_content(img, remove_nested=False):\n",
        "    layout_model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
        "    layout_output = layout_model.predict(img, batch_size=1, layout_nms=True)\n",
        "\n",
        "    table_boxes = []\n",
        "    for res in layout_output:\n",
        "        for box in res[\"boxes\"]:\n",
        "            if box[\"label\"] == \"table\":\n",
        "                coords = list(map(int, box[\"coordinate\"]))  # [x1,y1,x2,y2]\n",
        "                table_boxes.append(tuple(coords))\n",
        "\n",
        "    # Apply nested filtering if requested\n",
        "    if remove_nested:\n",
        "        table_boxes = filter_nested_tables(table_boxes)\n",
        "\n",
        "    return table_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScXo2LIgHnXc"
      },
      "outputs": [],
      "source": [
        "def subtract_overlap(box, overlap):\n",
        "    \"\"\"\n",
        "    Subtract overlap rectangle from box.\n",
        "    Args:\n",
        "        box: (x1, y1, x2, y2)\n",
        "        overlap: (ox1, oy1, ox2, oy2)\n",
        "    Returns:\n",
        "        list of remaining boxes after subtraction\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box\n",
        "    ox1, oy1, ox2, oy2 = overlap\n",
        "\n",
        "    remaining = []\n",
        "\n",
        "    # Top rectangle\n",
        "    if oy1 > y1:\n",
        "        remaining.append((x1, y1, x2, oy1))\n",
        "    # Bottom rectangle\n",
        "    if oy2 < y2:\n",
        "        remaining.append((x1, oy2, x2, y2))\n",
        "    # Left rectangle\n",
        "    if ox1 > x1:\n",
        "        remaining.append((x1, max(y1, oy1), ox1, min(y2, oy2)))\n",
        "    # Right rectangle\n",
        "    if ox2 < x2:\n",
        "        remaining.append((ox2, max(y1, oy1), x2, min(y2, oy2)))\n",
        "\n",
        "    return remaining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKMoaJZiH1wR"
      },
      "outputs": [],
      "source": [
        "def remove_overlapped_area(table_boxes):\n",
        "    \"\"\"\n",
        "    Removes overlapping areas but keeps the remaining parts of tables.\n",
        "    Args:\n",
        "        table_boxes: list of (x1,y1,x2,y2)\n",
        "    Returns:\n",
        "        list of boxes with overlaps removed\n",
        "    \"\"\"\n",
        "    # Sort by area (largest first)\n",
        "    table_boxes = sorted(table_boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)\n",
        "    result = []\n",
        "\n",
        "    for box in table_boxes:\n",
        "        temp = [box]\n",
        "        for kept in result:\n",
        "            new_temp = []\n",
        "            for t in temp:\n",
        "                inter_x1 = max(t[0], kept[0])\n",
        "                inter_y1 = max(t[1], kept[1])\n",
        "                inter_x2 = min(t[2], kept[2])\n",
        "                inter_y2 = min(t[3], kept[3])\n",
        "                if inter_x1 < inter_x2 and inter_y1 < inter_y2:\n",
        "                    # Overlap exists → subtract it\n",
        "                    new_temp.extend(subtract_overlap(t, (inter_x1, inter_y1, inter_x2, inter_y2)))\n",
        "                else:\n",
        "                    new_temp.append(t)\n",
        "            temp = new_temp\n",
        "        result.extend(temp)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQa0ioBYOF_5"
      },
      "outputs": [],
      "source": [
        "# Layout detection (rows and columns layout in tables)\n",
        "from paddleocr import TableStructureRecognition\n",
        "\n",
        "def detect_table_layout(img):\n",
        "  model = TableStructureRecognition(model_name=\"SLANet\")\n",
        "  output = model.predict(input=img, batch_size=1)\n",
        "  return output\n",
        "# for res in output:\n",
        "#     res.print(json_format=False)\n",
        "#     res.save_to_json(\"./output/res.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "965TFvy3SsFm"
      },
      "outputs": [],
      "source": [
        "# Put tables data into table layout based on\n",
        "# 8 point coordinates generated by PaddleOCR and\n",
        "# 4 point coordinates of words generated by DocTR\n",
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from itertools import groupby\n",
        "\n",
        "# ----------------------------\n",
        "# Helper functions\n",
        "# ----------------------------\n",
        "def quad_to_rect(quad):\n",
        "    \"\"\"Convert 8-point quadrilateral bbox to rectangle bbox (x0, y0, x1, y1)\"\"\"\n",
        "    xs = quad[0::2]\n",
        "    ys = quad[1::2]\n",
        "    return (min(xs), min(ys), max(xs), max(ys))\n",
        "\n",
        "def assign_text_to_cells(cells, text_boxes):\n",
        "    \"\"\"Assign each text box to the cell that contains its center\"\"\"\n",
        "    assigned = defaultdict(list)\n",
        "    for t in text_boxes:\n",
        "        tx0, ty0, tx1, ty1 = t['bbox']\n",
        "        center = ((tx0+tx1)/2, (ty0+ty1)/2)\n",
        "        for c in cells:\n",
        "            cx0, cy0, cx1, cy1 = c['bbox']\n",
        "            if cx0 <= center[0] <= cx1 and cy0 <= center[1] <= cy1:\n",
        "                assigned[c['cell_id']].append(t)\n",
        "                break\n",
        "    # Merge texts per cell\n",
        "    cell_text = {}\n",
        "    for cell_id, texts in assigned.items():\n",
        "        texts.sort(key=lambda t: t['bbox'][0])  # left to right\n",
        "        cell_text[cell_id] = ' '.join([t['text'] for t in texts])\n",
        "    return cell_text\n",
        "\n",
        "# ----------------------------\n",
        "# Main function\n",
        "# ----------------------------\n",
        "def paddleocr_doctr_to_df(paddleocr_output, doctr_text_boxes, row_threshold=10):\n",
        "    \"\"\"\n",
        "    Convert PaddleOCR + docTR output to Pandas DataFrame\n",
        "\n",
        "    Args:\n",
        "        paddleocr_output: dict, output from TableStructureRecognition\n",
        "        doctr_text_boxes: list of dicts, [{'text': 'abc', 'bbox': (x0,y0,x1,y1)}]\n",
        "        row_threshold: int, tolerance in pixels to separate rows\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame\n",
        "    \"\"\"\n",
        "    # Step 1: Convert quadrilaterals to rects\n",
        "    cells = []\n",
        "    for i, quad in enumerate(paddleocr_output['bbox']):\n",
        "        rect = quad_to_rect(quad)\n",
        "        cells.append({\n",
        "            'cell_id': i,\n",
        "            'bbox': rect,\n",
        "            'row_id': None,\n",
        "            'col_id': None\n",
        "        })\n",
        "\n",
        "    # Step 2: Infer row indices by top y-coordinate\n",
        "    cells.sort(key=lambda c: c['bbox'][1])\n",
        "    current_row = 0\n",
        "    last_y = -100\n",
        "    for c in cells:\n",
        "        y0 = c['bbox'][1]\n",
        "        if y0 - last_y > row_threshold:\n",
        "            current_row += 1\n",
        "            last_y = y0\n",
        "        c['row_id'] = current_row - 1  # 0-indexed\n",
        "\n",
        "    # Step 3: Infer column indices per row\n",
        "    df_rows = max(c['row_id'] for c in cells) + 1\n",
        "    df_cols = 0\n",
        "    for row_id, group in groupby(sorted(cells, key=lambda c: c['row_id']), lambda c: c['row_id']):\n",
        "        group = list(group)\n",
        "        group.sort(key=lambda c: c['bbox'][0])\n",
        "        for col_id, c in enumerate(group):\n",
        "            c['col_id'] = col_id\n",
        "        df_cols = max(df_cols, len(group))\n",
        "\n",
        "    # Step 4: Assign docTR text to cells\n",
        "    cell_text = assign_text_to_cells(cells, doctr_text_boxes)\n",
        "\n",
        "    # Step 5: Build DataFrame\n",
        "    df = pd.DataFrame(\"\", index=range(df_rows), columns=range(df_cols))\n",
        "    for c in cells:\n",
        "        row, col = c['row_id'], c['col_id']\n",
        "        df.iat[row, col] = cell_text.get(c['cell_id'], \"\")\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5seauONc5tP3"
      },
      "outputs": [],
      "source": [
        "#  Filter DocTR OCR text outside table boxes\n",
        "\n",
        "def inside_table(box, tables):\n",
        "    x1, y1, x2, y2 = box\n",
        "    for tx1, ty1, tx2, ty2 in tables:\n",
        "        if x1 >= tx1 and y1 >= ty1 and x2 <= tx2 and y2 <= ty2:\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da6hxVsFVkl2"
      },
      "outputs": [],
      "source": [
        "# Extract words with boxes and scores\n",
        "def extract_table_words_with_bboxes(json_ocr_result):\n",
        "    words = []\n",
        "    for page in json_ocr_result['pages']:\n",
        "        for block in page['blocks']:\n",
        "            for line in block['lines']:\n",
        "                for word in line['words']:\n",
        "                    text = word['value'].strip()\n",
        "                    if text:  # Skip empty\n",
        "                        score = word['confidence']\n",
        "                        geometry = np.array(word['geometry'])  # [[x0,y0], [x1,y1]] for word bbox (quad? but often bilinear)\n",
        "                        # Convert to polygon if needed (DocTR uses bilinear quads, but for simplicity, use corners)\n",
        "                        poly = np.array(geometry).reshape(2, 2) * np.array([crop.shape[1], crop.shape[0]])  # Scale to image coords if normalized\n",
        "                        words.append({'text': text, 'score': score, 'poly': poly})\n",
        "\n",
        "    print(f\"Detected {len(words)} words in table.\")\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXLwaTj41_Bu"
      },
      "source": [
        "# Section Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc3nJ6rL2EFW"
      },
      "outputs": [],
      "source": [
        "# Section Detection\n",
        "def detect_section_type(line_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Detect if a line is a SECTION, SUBSECTION, HEADING, PARAGRAPH, or KEY.\n",
        "    Rules:\n",
        "    - Roman numeral + CAPS = SECTION\n",
        "    - Single capital letter + CAPS = SUBSECTION\n",
        "    - ALL CAPS = KEY\n",
        "    - Capital + lowercase = value/paragraph\n",
        "    \"\"\"\n",
        "    import re\n",
        "    if re.match(r\"^(I|II|III|IV|V|VI|VII|VIII|IX|X)\\.\\s+[A-Z ]+$\", line_text):\n",
        "        return \"SECTION\"\n",
        "    elif re.match(r\"^[A-Z]\\.\\s+[A-Z ]+$\", line_text):\n",
        "        return \"SUBSECTION\"\n",
        "    elif line_text.isupper():\n",
        "        return \"KEY\"\n",
        "    elif re.match(r\"^[A-Z][a-z]\", line_text):\n",
        "        return \"PARAGRAPH\"\n",
        "    else:\n",
        "        return \"UNKNOWN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQe3Hm172OiP"
      },
      "outputs": [],
      "source": [
        "# Key-Value Extraction\n",
        "def extract_key_value_pairs(lines: List[str]) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Identify keys and values.\n",
        "    - All Caps word = Key\n",
        "    - Next line or same line = Value\n",
        "    \"\"\"\n",
        "    key_values = {}\n",
        "    current_key = None\n",
        "\n",
        "    for line in lines:\n",
        "        if line.isupper():\n",
        "            current_key = line\n",
        "            key_values[current_key] = \"\"\n",
        "        else:\n",
        "            if current_key:\n",
        "                key_values[current_key] += (\" \" + line).strip()\n",
        "    return key_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NYal6xv2T0Y"
      },
      "outputs": [],
      "source": [
        "# Section REconstruction\n",
        "def reconstruct_document(lines: List[List[Word]]) -> Dict:\n",
        "    \"\"\"\n",
        "    Build hierarchical structure: Sections -> Subsections -> Content.\n",
        "    \"\"\"\n",
        "    document = {}\n",
        "    current_section = None\n",
        "    current_subsection = None\n",
        "\n",
        "    for line in lines:\n",
        "        line_text = merge_line_text(line)\n",
        "        section_type = detect_section_type(line_text)\n",
        "\n",
        "        if section_type == \"SECTION\":\n",
        "            current_section = line_text\n",
        "            document[current_section] = {}\n",
        "        elif section_type == \"SUBSECTION\" and current_section:\n",
        "            current_subsection = line_text\n",
        "            document[current_section][current_subsection] = []\n",
        "        elif section_type == \"KEY\" and current_section:\n",
        "            if current_subsection:\n",
        "                document[current_section][current_subsection].append({line_text: \"\"})\n",
        "            else:\n",
        "                document[current_section][line_text] = \"\"\n",
        "        else:\n",
        "            if current_section:\n",
        "                if current_subsection:\n",
        "                    document[current_section][current_subsection].append(line_text)\n",
        "                else:\n",
        "                    document[current_section].setdefault(\"Content\", []).append(line_text)\n",
        "    return document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKEL_EEU0RCj"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-sWkJzL0f0-"
      },
      "source": [
        "#### 1. Load PDF and convert to Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuyp5MXj0WiR",
        "outputId": "368e271c-ef98-4c67-c4f8-a4099624fe5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ocr_test/page0.png\n",
            "Saved: ocr_test/page1.png\n",
            "Saved: ocr_test/page2.png\n",
            "Saved: ocr_test/page3.png\n",
            "Saved: ocr_test/page4.png\n",
            "Saved: ocr_test/page5.png\n"
          ]
        }
      ],
      "source": [
        "# Load and Convert\n",
        "pdf_path = \"/content/testscanneddocs.pdf\"\n",
        "pages = convert_to_images(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ8xJS3V0d0g"
      },
      "outputs": [],
      "source": [
        "# Read Images\n",
        "images_path = \"/content/ocr_test\"\n",
        "images = os.listdir(images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzicjVvyUodk",
        "outputId": "98ae4d25-cfd8-4e79-d98d-a7ccfb26ff6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['page0.png', 'page2.png', 'page5.png', 'page4.png', 'page3.png', 'page1.png']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odz7Cy7ABFDE"
      },
      "outputs": [],
      "source": [
        "# Read an Image\n",
        "img = os.path.join(images_path,images[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIi9iiQPUX8K"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "image = cv2.imread(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icAMS4yU02LU"
      },
      "source": [
        "#### 2. Run OCR on Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJjQPWKi05R0"
      },
      "outputs": [],
      "source": [
        "# Run Ocr and get bounding boxes\n",
        "\n",
        "doc = DocumentFile.from_images(img)\n",
        "ocr_model = ocr_predictor(pretrained=True)\n",
        "ocr_result = ocr_model(doc)\n",
        "\n",
        "ocr_text_boxes = []\n",
        "for page in ocr_result.pages:\n",
        "    h, w = page.dimensions\n",
        "    for block in page.blocks:\n",
        "        for line in block.lines:\n",
        "            for word in line.words:\n",
        "                (x_min, y_min), (x_max, y_max) = word.geometry\n",
        "                x_min, x_max = int(x_min * w), int(x_max * w)\n",
        "                y_min, y_max = int(y_min * h), int(y_max * h)\n",
        "                ocr_text_boxes.append({\n",
        "                    \"text\": word.value,\n",
        "                    \"bbox\": (x_min, y_min, x_max, y_max)\n",
        "                })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJHbYWNU4EqV"
      },
      "outputs": [],
      "source": [
        "# Pipeline\n",
        "words = ocr_text_boxes\n",
        "words = preprocess_words(words)\n",
        "lines = group_words_into_lines(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyCfJy6L4a9r"
      },
      "outputs": [],
      "source": [
        "print(format_lines_with_spacing(lines, scale=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5DTxs5kAM5A"
      },
      "source": [
        "# Detect and Extract Table Content with DocTR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvpzjywJC2mZ"
      },
      "source": [
        "### 1. Detect and Crop the table Region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlzqzUL_AOTv",
        "outputId": "39cabd79-9aed-446b-e11c-21e6d9f390fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-DocLayout_plus-L`.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "table_boxes = detect_table_content(img, remove_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwwwzkCJUA7x",
        "outputId": "80871ede-2fe1-4acd-f189-e293c84bec4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(table_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmGnzobtClaP"
      },
      "outputs": [],
      "source": [
        "# Crop the table region\n",
        "for idx,tb in enumerate(table_boxes):\n",
        "    x1, y1, x2, y2 = tb\n",
        "    crop = image[y1:y2, x1:x2]\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the cropped area\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(crop)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oARV-KzG9HYR"
      },
      "source": [
        "#### Filter the page text by removing content of table from it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WKzczSG8alo"
      },
      "outputs": [],
      "source": [
        "filtered_texts = [t for t in ocr_text_boxes if not inside_table(t[\"bbox\"], table_boxes)]\n",
        "filtered_lines = group_words_into_lines(filtered_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXMEFzP58cCp",
        "outputId": "83752da0-baaf-4886-b5a2-42cdc71b4ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BID SLAIE DEVELOPMENT\n"
          ]
        }
      ],
      "source": [
        "print(format_lines_with_spacing(filtered_lines, scale=40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL5XDDOmDCAL"
      },
      "source": [
        "### 2. OCR the detected Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy5ceRNoAbdv",
        "outputId": "0e4ba697-b6cb-4266-b04c-dac94bedc5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DocTR model loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load OCR Model\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "# Initialize the predictor (use 'db_resnet50' for detection, 'crnn_vgg16_bn' for recognition; or 'vit' for better accuracy)\n",
        "model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
        "# For GPU: model = ocr_predictor(..., device='cuda:0')\n",
        "print(\"DocTR model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKUvCUroVIun"
      },
      "outputs": [],
      "source": [
        "result = model([crop])  # Input: np.array (H, W, 3) or DocumentFile.from_images('path')\n",
        "json_result = result.export()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnQtQ5-VVdm",
        "outputId": "c42bf5dd-632f-4b04-a77d-7f12444e69aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected 437 words in table.\n"
          ]
        }
      ],
      "source": [
        "table_words = extract_table_words_with_bboxes(json_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR9Vm15P_bbC"
      },
      "outputs": [],
      "source": [
        "table_ocr_text_boxes = []\n",
        "for page in result.pages:\n",
        "    h, w = page.dimensions\n",
        "    for block in page.blocks:\n",
        "        for line in block.lines:\n",
        "            for word in line.words:\n",
        "                (x_min, y_min), (x_max, y_max) = word.geometry\n",
        "                x_min, x_max = int(x_min * w), int(x_max * w)\n",
        "                y_min, y_max = int(y_min * h), int(y_max * h)\n",
        "                table_ocr_text_boxes.append({\n",
        "                    \"text\": word.value,\n",
        "                    \"bbox\": (x_min, y_min, x_max, y_max)\n",
        "                })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_ocr_text_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4dV6QhbW5wt"
      },
      "source": [
        "### 3. Detect Layout Coordinates of Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZinVNTrXJmF",
        "outputId": "3b8bbe3e-9481-4999-8bc7-e76348088369"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/SLANet`.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Layout detection (text in tables)\n",
        "table_layout_coords = detect_table_layout(crop)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxJlVsPvTaKX"
      },
      "outputs": [],
      "source": [
        "df = paddleocr_doctr_to_df(table_layout_coords, table_ocr_text_boxes)\n",
        "df.columns = df.iloc[0]\n",
        "# Drop the first row from the DataFrame\n",
        "df = df.drop(0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OohcaL-3YA5M"
      },
      "outputs": [],
      "source": [
        "tbl_markdown = df.to_markdown(index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tbl_markdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-oSI_un4W23"
      },
      "outputs": [],
      "source": [
        "# filtered_texts = [t for t in ocr_text_boxes if not inside_table(t[\"bbox\"], table_boxes)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = []\n",
        "switch = True\n",
        "for t in ocr_text_boxes:\n",
        "  if inside_table(t[\"bbox\"], table_boxes) and switch:\n",
        "    test.append({\"table\":tbl_markdown})\n",
        "    switch = False\n",
        "  elif inside_table(t[\"bbox\"], table_boxes) and not switch:\n",
        "    continue\n",
        "  else:\n",
        "    test.append(t)\n",
        "    switch = True\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in test:\n",
        "  if \"table\" in i:\n",
        "    print(i[\"table\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEsHgrru9uYq"
      },
      "outputs": [],
      "source": [
        "test_lines = group_words_and_tables_into_lines(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(render_text_and_tables_from_ocr(test_lines, scale=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CRuHx64AHjY"
      },
      "outputs": [],
      "source": [
        "# table_words = preprocess_words(table_ocr_text_boxes)\n",
        "# table_lines = group_words_into_lines(table_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo6jgHRaCUbk"
      },
      "outputs": [],
      "source": [
        "# # Merge text + tables in reading order\n",
        "# merged = [{\"type\": \"text\", \"text\": t[\"text\"], \"bbox\": t[\"bbox\"]} for t in filtered_texts]\n",
        "# merged += [{\"type\": \"table\", \"text\": tbl_markdown, \"bbox\": tbl[\"bbox\"]} for tbl in table_contents]\n",
        "\n",
        "# # Sort top-to-bottom, left-to-right\n",
        "# merged.sort(key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZmifIF2Zf6T"
      },
      "outputs": [],
      "source": [
        "# merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DL3uJp7Aw1a"
      },
      "outputs": [],
      "source": [
        "# # Print final output\n",
        "# final_output = []\n",
        "# for item in merged:\n",
        "#     if item[\"type\"] == \"text\":\n",
        "#         final_output.append(item[\"text\"])\n",
        "#     else:\n",
        "#         final_output.append(\"\\n\" + item[\"text\"] + \"\\n\")\n",
        "\n",
        "# print(\" \".join(final_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hQgXqSS-P8J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
